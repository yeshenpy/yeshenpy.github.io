<!DOCTYPE html>
<head>
    <title>Pengyi Li</title>
    <meta name="author" content="Pengyi Li">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta property="og:title" content="Pengyi Li">
	<meta property="og:description" content="PhD student, Tianjin University">
    <meta property="og:image" content="https://yeshenpy.github.io/files/me.jpg">
    <link rel="apple-touch-icon" href="files/ucsd-logo.png">
    <link rel="icon" type="image/png" href="files/ucsd-logo.png">
    <link rel="manifest" href="files/site.webmanifest">
    <link rel="stylesheet" href="style.css">
</head>

<div class="header noselect">
    <div class="content row">
        <div class="header-profile-picture"></div>
        <div class="header-text">
            <div class="header-name">
                <h1>Pengyi Li</h1>
            </div>
            <div class="header-subtitle">
                PhD student, Tianjin University
            </div>
            <div class="header-links">
                <a class="btn" href="#contact">Email</a> /
                <a class="btn" href="https://scholar.google.com/citations?user=U9tjvNUAAAAJ&hl=zh-CN">Google Scholar</a> /
                <a class="btn" href="https://github.com/yeshenpy">GitHub</a> /
                <a class="btn" href="xxxx">Twitter</a> /
                <a class="btn" href="https://www.zhihu.com/people/ye-shen-83-32">Zhihu</a> /
            </div>
        </div>
    </div>
</div>
<div class="content" style="padding-bottom: 64px;">
    <div>
        <p>
	    I am a second-year PhD student at Deep Reinforcement Learning (DRL) Lab, Tianjin University (TJU), advised by Prof. Jianye Hao. I am also co-advised by Prof. Yan Zheng. I received my Bachelor's degree from the TianJin University too.
	</p>
    </div>
    <div>
        <h2 class="noselect">Research interest</h2>
        <p>
	   I focus on research on the <span class="bold">Reinforcement Learning</span> and <span class="bold">Evolutionary Algorithms</span>, which include <span class="bold">Multi-agent Reinforcement Learning, Multi-objective Reinforcement Learning, Multi-task Reinforcement Learning, and Evolutionary Reinforcement Learning</span>. Recently, my emphasis has been on how to build better policy search algorithms and general policy.
        </p>
    </div>
    <div>
        <h2 class="noselect">Publications and preprints</h2>
        <p>Papers sorted by recency. Representative papers are <span style="background-color: #fff8df">highlighted</span>.</p>
	<div class="publication row clearfix">
            <div class="row-media" style="background-image: url(files/diffusion_lite.jpg);"></div>
            <div class="row-text">
                <a class="publication-title bold" href="https://arxiv.org/abs/2401.15443">DiffuserLite: Towards Real-time Diffusion Planning</a><br/>
                Zibin Dong, Jianye Hao, Yifu Yuan, Fei Ni, Yitian Wang, <span class="bold">Pengyi Li</span>, Yan Zheng<br/>
                <span class="italic">Arxiv Preprint(<a href="https://arxiv.org/abs/2401.15443">Arxiv</a></span>), 2024<br/>
                <a class="btn btn-red" href="https://arxiv.org/abs/2401.15443">arXiv</a> / <a class="btn btn-dark" href="bibtex/diffusion_lite">bibtex</a>
            </div>
        </div>
        <div class="highlight publication row clearfix">
            <div class="row-media" style="background-image: url(files/bridge.jpg);"></div>
            <div class="row-text">
                <a class="publication-title bold" href="https://arxiv.org/abs/2401.11963">Bridging Evolutionary Algorithms and Reinforcement Learning: A Comprehensive Survey</a><br/>
                <span class="bold">Pengyi Li</span>, Jianye Hao, Hongyao Tang, Xian Fu, Yan Zheng, Ke Tang<br/>
                <span class="italic">Arxiv Preprint(<a href="https://arxiv.org/abs/2401.11963">Arxiv</a></span>), 2024<br/>
                <a class="btn btn-orange" href="https://github.com/yeshenpy/Awesome-Evolutionary-Reinforcement-Learning">Github Repository</a> / <a class="btn btn-red" href="https://arxiv.org/abs/2401.11963">arXiv</a> / <a class="btn btn-dark" href="bibtex/bridge">bibtex</a>
            </div>
        </div>
        <div class="publication row clearfix">
            <div class="row-media" style="background-image: url(files/CCQD.jpg);"></div>
            <div class="row-text">
                <a class="publication-title bold" href="https://openreview.net/forum?id=JDud6zbpFv">Sample-Efficient Quality-Diversity by Cooperative Coevolution</a><br/>
                Ke Xue, Ren-Jian Wang, <span class="bold">Pengyi Li</span>, Dong Li, Jianye HAO, Chao Qian<br/>
                <span class="italic">International Conference on Learning Representations (<a href="https://iclr.cc">ICLR</a></span>), 2024<br/>
                <a class="btn btn-orange" href="https://robotics-transformer-x.github.io">project page</a> / <a class="btn btn-red" href="https://openreview.net/forum?id=JDud6zbpFv">OpenReview</a> / <a class="btn" href="https://openreview.net/forum?id=JDud6zbpFv">code</a>  / <a class="btn btn-dark" href="bibtex/CCQD">bibtex</a>
            </div>
        </div>
        <div class="highlight publication row clearfix">
            <div class="row-media" style="background-image: url(files/RACE.jpg);"></div>
            <div class="row-text">
                <a class="publication-title bold" href="https://proceedings.mlr.press/v202/li23i.html">RACE: Improve Multi-Agent Reinforcement Learning with Representation Asymmetry and Collaborative Evolution</a><br/>
                 <span class="bold">Pengyi Li</span>, Jianye Hao, Hongyao Tang, Yan Zheng, Xian Fu<br/>
                <span class="italic">International Conference on Machine Learning (<a href="https://icml.cc">ICML</a></span>), 2023<br/>
                <a class="btn btn-red" href="https://proceedings.mlr.press/v202/li23i.html">Link</a> / <a class="btn" href="https://github.com/yeshenpy/RACE">code</a> / <a class="btn btn-dark" href="bibtex/RACE.txt">bibtex</a>
            </div>
        </div>
        <div class="highlight publication row clearfix">
            <div class="row-media" style="background-image: url(files/ERL-Re2.jpg);"></div>
            <div class="row-text">
                <a class="publication-title bold" href="https://arxiv.org/abs/2210.17375">ERL-Re^2: Efficient Evolutionary Reinforcement Learning with Shared State Representation and Individual Policy Representation</a><br/>
                Jianye Hao, <span class="bold">Pengyi Li</span> (Student First Author), Hongyao Tang, Yan Zheng, Xian Fu, Zhaopeng Meng<br/>
                <span class="italic">International Conference on Learning Representations (<a href="https://iclr.cc">ICLR</a>)</span>, 2023</span><br/>
                <a class="btn btn-red" href="https://arxiv.org/abs/2210.17375">arXiv</a> / <a class="btn" href="https://github.com/yeshenpy/ERL-Re2">code</a> / <a class="btn btn-dark" href="bibtex/ERL-Re2.txt">bibtex</a>
            </div>
        </div>
        <div class="highlight publication row clearfix">
            <div class="row-media" style="background-image: url(files/PMIC.jpg);"></div>
            <div class="row-text">
                <a class="publication-title bold" href="https://proceedings.mlr.press/v162/li22s.html">PMIC: Improving Multi-Agent Reinforcement Learning with Progressive Mutual Information Collaboration</a><br/>
                <span class="bold">Pengyi Li</span>, Hongyao Tang, Tianpei Yang, Xiaotian Hao, Tong Sang, Yan Zheng, Jianye Hao, Matthew E. Taylor, Wenyuan Tao, Zhen Wang<br/>
                <span class="italic">International Conference on Machine Learning (<a href="https://icml.cc">ICML</a>)</span>, 2022 </span><br/>
                <a class="btn btn-red" href="https://proceedings.mlr.press/v162/li22s.html">Link</a> / <a class="btn" href="https://github.com/yeshenpy/PMIC">code</a> / <a class="btn btn-dark" href="bibtex/PMIC.txt">bibtex</a>
            </div>
        </div>
        <div class="publication row clearfix">
            <div class="row-media" style="background-image: url(files/hyar.jpg);"></div>
            <div class="row-text">
                <a class="publication-title bold" href="https://arxiv.org/abs/2109.05490">Hyar: Addressing discrete-continuous action reinforcement learning via hybrid action representation</a><br/>
                Boyan Li, Hongyao Tang, Yan Zheng, Jianye Hao, <span class="bold">Pengyi Li</span>, Zhen Wang, Zhaopeng Meng, Li Wang<br/>
                <span class="italic">International Conference on Learning Representations (<a href="https://iclr.cc">ICLR</a>)</span>, 2022<br/>
                <a class="btn btn-red" href="https://arxiv.org/abs/2109.05490">arXiv</a> / <a class="btn btn-dark" href="bibtex/HYAR.txt">bibtex</a>
            </div>
        </div>
    
    </div>
    <div>
        <h2 class="noselect">Misc. open-source projects</h2>
        <div class="publication row clearfix">
            <div class="row-media" style="background-image: url(files/git_bridge.jpg);"></div>
            <div class="row-text">
                <a class="bold" href="https://github.com/yeshenpy/Awesome-Evolutionary-Reinforcement-Learning">Awesome-Evolutionary-Reinforcement-Learning<span class="stars">&#11088; 69</span></a><br/>
                <span class="bold">Pengyi Li</span><br/>
                May 2023<br/>
                <a class="btn btn-orange" href="https://github.com/yeshenpy/Awesome-Evolutionary-Reinforcement-Learning">project page</a> / <a class="btn btn-red" href="https://arxiv.org/abs/2401.11963">Paper</a> / <a class="btn btn-dark" href="bibtex/bridge.txt">bibtex</a>
            </div>
        </div>
        <div class="publication row clearfix">
            <div class="row-media" style="background-image: url(files/git_re2.jpg);"></div>
            <div class="row-text">
                <a class="bold" href="https://github.com/yeshenpy/ERL-Re2">ERL-Re^2 Implementation <span class="stars">&#11088; 38</span></a><br/>
                <span class="bold">Pengyi Li</span><br/>
                February 2023<br/>
                <a class="btn btn-orange" href="https://github.com/yeshenpy/ERL-Re2">project page</a> / <a class="btn btn-red" href="https://arxiv.org/abs/2210.17375">Paper</a> / <a class="btn btn-dark" href="bibtex/ERL-Re2.txt">bibtex</a>
            </div>
        </div>
        <div class="publication row clearfix">
            <div class="row-media" style="background-image: url(files/git_RACE.jpg);"></div>
            <div class="row-text">
                <a class="bold" href="https://github.com/yeshenpy/RACE">RACE Implementation <span class="stars">&#11088; 19</span></a><br/>
                <span class="bold">Pengyi Li</span><br/>
                May 2023<br/>
                <a class="btn btn-orange" href="https://github.com/yeshenpy/RACE">Github</a> / <a class="btn" href="https://proceedings.mlr.press/v202/li23i.html">Paper</a>
            </div>
        </div>
        <div class="publication row clearfix">
            <div class="row-media" style="background-image: url(files/git_PMIC.jpg);"></div>
            <div class="row-text">
                <a class="bold" href="https://github.com/yeshenpy/PMIC">PMIC Implementation<span class="stars">&#11088; 13</span></a><br/>
                <span class="bold">Pengyi Li</span><br/>
                September 2022<br/>
                <a class="btn btn-red" href="https://github.com/yeshenpy/PMIC">Github</a> / <a class="btn" href="https://proceedings.mlr.press/v162/li22s.html">Paper</a> / <a class="btn btn-dark" href="bibtex/PMIC.txt">bibtex</a>
            </div>
        </div>
    </div>
    <div>
        <h2 class="noselect">Press coverage</h2>
        I have been mentioned in various media in connection with my research. Here's a few selected articles:
        <div class="row clearfix" style="margin-top: 16px;">
            <a href="https://generallyintelligent.com/podcast/2022-12-16-podcast-episode-25-nicklas-hansen/" class="press row-media" style="background-image: url(files/generallyintelligent.png)"></a>
            <a href="https://bdtechtalks.com/2022/04/04/reinforcement-learning-td-mpc/" class="press row-media" style="background-image: url(files/bdtalks.png)"></a>
            <a href="https://bair.berkeley.edu/blog/2021/02/25/ss-adaptation/" class="press row-media" style="background-image: url(files/bair.png)"></a>
            <a href="https://blog.deeplearning.ai/blog/the-batch-predicting-car-crashes-profiting-from-deepfakes-piloting-drone-swarms-grading-data" class="press row-media" style="background-image: url(https://i.imgur.com/eoASzgo.png)"></a>
        </div>
    </div>
    <div class="noselect">
        <a id="contact"></a>
        <h2>Contact</h2>
        You are very welcome to contact me regarding my research. I typically respond within a few days.<br/>
        I can be contacted directly at <span class="bold">lipengyi</span> [at] <span class="bold">tju.edu.cn</span>
    </div>
</div>
